{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d377b2ce",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4091fef",
   "metadata": {},
   "source": [
    "A little exploration of some neural network frameworks, hoping to grasp more specifically recurrent neural networks, and reservoir computing, specially those directed towards physical reservoir computing, using in vitro/in vivo systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453837cb",
   "metadata": {},
   "source": [
    "One of the central interests comes from the prediction and reconstruction of time-series. A very nice characteristic of in vitro/in vivo systems, is that they have been under the \"evolutionary test\" for a reasonable amount of time, such that emerging from resource scarce conditions, majority of times, if not all, a bet-hedging scheme appears, along with majority of substrates in this respective system being multi-functional. This out of itself is pressed by a necessity not to optimize for what we perceive to be a single metric, but to minmax for an enormous set of them. After that, what would be an individual with its own incentives, is usually merged with other ones of the same scale, resulting in larger-scale networks that inherently constrain the state-space exploration of its constituents. \n",
    "All of this to say: There's lots of non-linear dynamics to be harvested and to be used as a reservoir for time-series prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bd8bde",
   "metadata": {},
   "source": [
    "Furthermore, when talking about convergence to a certain state, or for that manner a set of them, taking into account the multi-functional charactertistic that majority of components take, we'll always have a minmax scheme. Or atleast something that is perceived as such, such that the feedback loops respective to such system being considered don't have enough or perfect resolution, for such systems to be considered fully deterministic. That, and what follows from game-theory after that: Exploit to the extent of not being exploited to failure. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13af8e98",
   "metadata": {},
   "source": [
    "### On finding other abstractions in biology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89d0360",
   "metadata": {},
   "source": [
    "Perhaps we can state that some of the abstractions we have found successful in biology are themselves general principles. However, how many of these abstractions can we really say pertrain to the biological world. There's fundamentally no organism being described. Perhaps we don't have the mathematics for it yet.\n",
    "As another contender, we might instead dwelve into a relational approach, instead of relying in a mechanistic one, with category theory. However, again, is this approach not inherently too hard bounded? The moment we say that a certain object pertrains to a specific set, or to a finite amount of them, encapsulating some function, and then building on top of it some category, functor, or natural transformation, we are inherently missing the point. In the biological world, everything goes. In the sense that even if some protein has a known function (high correlation mechanism), it still partakes in the cellular milieu, and as such, is associated with every other perceptible \"function\", or for that manner every other that we can abstract.\n",
    "Are there other approaches to be discovered, that we have funnelled ourselves out of? For example, regarding heredity of form relative to multicellular systems. Who cares about preservation of genome, if they preserve the same geometry. What about the amount of heat released, and associated fluctuations? Can we link the thermodynamic/information-theoretic approach to biology?\n",
    "The problem is that physics seems indeed to be the exception, and biology the rule (this in terms of what types of systems and the way we describe their behaviour in each field).\n",
    "How can I form reasonable enough abstractions about systems with an unbelievable amount of compression? \n",
    "And then take into account looping realization that we aren't spectators. It also applies to us, whatever type of dynamics and constraints of exploration that you see across Nature, also limit our formalizations and abstractions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fe9f5e-c4f0-43e7-b4d0-2a600cd789a6",
   "metadata": {},
   "source": [
    "#### Small notes on [Evolution \"On Purpose\": Teleonomy in Living Systems](https://direct.mit.edu/books/oa-edited-volume/5634/Evolution-On-Purpose-Teleonomy-in-Living-Systems) \n",
    "\n",
    "Whilst a good part of biology as a whole can be stated to be devoid of the organism, as pertaining to having a good theory of emergence relying on concepts like autopoiesis, autocatalysis, closure of constraints, and any other concept that tries to model the relation: constraints of a system dictate the dynamics, and the dynamics lead to an update of the constraints; it is nonetheless even more of an insormountable task given that we are not spectators. We are ourselves wholes, and parts at the same time, and as such our perceptions and through extention our formal systems (or the ones we can build) are themselves at mercy of an evolutionary process that usually tends to benefit robustness, in this case of larger scale networks, these ones enabling and perpetuating the conditions that gave rise to us (here largely thinking that a good chunck of bad options, has been selected out through evolutionary funnels).\n",
    "\n",
    "Regarding the concept of teleonomy, we can perhaps state that it exists such that living systems have an internal \"purposiveness\" or a collection of goal-states they act towards, and usually being characteristic of non-equilibrium systems. Also, atleast on this last remark, on long evolutionary scales, systems that have a better perception, and that themselves develop a more robust teleonomy, are going to be selected, as they can better model a world with other such systems they need to cooperate, compete, and merge with. Furthermore, living systems literally build themselves, such that fundamentally the biggest problem in addressing them, is mimicking and building a system that rebuilds over and over the perception of its own boundaries, whilst using a very complex internal antecipation system. This type of antecipation would rely on every part of the whole system, also being a whole itself with its own incentives (or goal-states), such that small changes in degrees of freedom in smaller parts would be allocated and propagated throughout a larger whole, resulting in the larger whole morphing the state-space of the smaller wholes so as to meet its own incentives. An important divergence from modern evolutionary synthesis, is that it's easier to change a system through exploration of larger-scale modules, than through micromanaging lower-scale ones (wrt majority of cases of course).\n",
    "\n",
    "It is also perhaps important to note that this notion of internal \"purposiveness\" can also be seen merely through an analogue of state-space evolution, although only if seen by an \"observer-system\" that shares low to no information of the respective internal model. In fact, any type of dynamical system, specially non-equilibrium ones, can be put through this lens, and come out as having an internal drive, or set of goal-states (states it oscillates around and converges to). The huge problem on relying solely in describing the state-space of biological systems and using it for prediction, is that pre-stating such state-space and saying it predicts something reasonable, is usually the same as saying that such system stopped in time, with no other influences affecting it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56961414-3cb1-4d2e-bae5-c7e4a04b9f66",
   "metadata": {},
   "source": [
    "### Regarding Intelligence\n",
    "An intelligent system would perhaps first and foremost be characterized by autopoiesis, by the capacity to literally build itself. Such systems, even ones with larger-scale organization, like social ones, are themselves intelligent, given that they have constituents showing these capacities. Each constituent, and consequently each sub-network formed by combinatorial relations between these constituents will also have autopoietic capacities, and respectively have its own incentives. This is where intelligence stems from. Initially, larger-scale networks, will seem to lack these capacities, but as they form more robust constraints, limiting the state-space exploration of its constituents, such capacities will emerge, through self-preservation. As such, overtime they will have more refined control over the update of their own boundaries. \n",
    "\n",
    "If from the start, smaller parts forming the larger whole lack these capacities, the \"emerging\" larger-scale system, will not be considered intelligent. If there is no coarse-graining between scales, if there is micromanaging of lower-scale networks, there probably won't be any type of intelligence to such system being described. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae97c41b-63bc-4b07-8297-44b96116600b",
   "metadata": {},
   "source": [
    "### Regarding memory\n",
    "If we take memory to be the capacity to converge to a state or to a set of them, general dynamical systems are not so much different than biological systems. Both these systems have their state space evolution depending on the respective input applied. However, in biological systems there's a much larger combinatorial allocation possible, given coarse-graining over scales. Not only are those memories that are realized by the current state space kept, but also those that are in \"vicinity\" of such state space. And given the amount of variance (resulting from multiple agents with their own incentives, forming a larger scale system), there's a huge set of memories being kept, that wildly surpasses the type of memory allocation that we have in digital systems. Just imagine other types of architechtures that wouldn't rely on micromanaging memory preservation. This huge set of memories being kept, that at a certain point could simply be perceived as \"learned behaviours\" (as opposed to simple mechanism, in lower scale systems, for example considering molecular biology) in larger scale systems, is therefore at a reasonable reach given a few \"inputs\".\n",
    "\n",
    "Everything is useful in the biological world, even \"waste\" heat resulting from some enzimatic reactions leading to increased diffusion rates for other molecules. There no such thing as a non-relation. Everything is related. A measurement is a relation. As such, what's missing in biology is precisely the study of the organism.\n",
    "\n",
    "Furthermore, considering both general dynamical systems and biological ones, to be in a scenario where they are deprived from external inputs, the state-space evolution of these biological systems is so much richer and more complex, that they actually look as if they have an \"internal drive\", or teleonomy. There is an appearance of exploration, that is characterized by an updating of the system's constraints, without relying heavily on external inputs. This is where intelligence presumably stems from. The capacity to make use of every attribute of the system, leading to a robust exploration capability. I would presume intelligence is actually linked to this type of memory. One that is highly non-rigid, given that for a respective input there's propagation and allocation of it over a great range of the total degrees of freedom of the system. Such is the case, that traditional evolutionary synthesis would be put to the corner, given the huge magnitude of adaption capabilities demonstrated by biological systems, specially when dealing with novel perturbations, being largely unexplainable by simply refering to memory allocation in DNA, RNA, cytoskeleton components, etc (and scaling up the dimensions of the system). These are what we can reasonably abstract. What about those we can't? Do we simply ignore them? \n",
    "\n",
    "Regarding what was mentioned about teleonomy, the type of behaviour being described is the same, either if seen by a process philosophy lense, or one alligned more with a material-deterministic one. It's the same thing being described by two different perspectives, and we shouldn't \"choose a side\" here. Whatever works, works. There's something very ironic about clinging so much to a single perspective, given that the perception of the \"sublime\" is largely unachievable. There's too much evolutionary momentum, and too much compression, for us to lose so much time not exploring every perspective we have at our reach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d088d63-8326-42ab-930a-c2b5ce1f2182",
   "metadata": {},
   "source": [
    "### More on memory\n",
    "\n",
    "If we take, again, memory to be the capacity to converge to a state, or to a set of them, each system, as a whole and as constituent, of a larger scale one, will have a \"goal-state\", $\\Delta$, it gravitates towards. Furthermore, if we are to abstract such dynamics in a landscape, such system is invariably decreasing its suprisal (regarding free energy principle) given its environment. As such, the respective system would inherently be in a location of its state-space, where suprisal is minimized (where its dynamics most accurately predict the environment it is in). Moreover, such system would probably have dissipation, by heat released, as $\\Delta Q \\propto \\epsilon_{\\Delta}$. Having heat released proportional to the distance to its \"goal-state\", $\\epsilon_{\\Delta}$. This is for a single scale. However, one ought to see this as a multi-agent relation. Where each agent has it own \"goal-state\" $\\Delta$. Furthermore, systems of larger-scale will inherently morph the state-space of its constituents so as to meet their own goal-states.\n",
    "\n",
    "Intelligence would presumably be linked to the capacity of generalization. In this case, such would represent having low-transition costs, between funnels in the landscape. In other words, no hard convergence to a set of states. To the point that, even with internal dynamics of its constituents, and little external inputs, a larger scale system would be able to adapt robustly with little effort to new pertubations. \n",
    "\n",
    "As such, one would presumably see $\\Delta Q \\propto m^{\\alpha}$, with $\\alpha < 1$. As systems increase in mass, they would invariably have to coarse-grain over scales, if they are to be considered evolutionary successfull (and emerging out of resource-scarcity).\n",
    "\n",
    "On this matter systems that employ micro-managing of lower-scales would be at a disadvantage, as they would tipically hard converge to a set of states, losing generality. \n",
    "\n",
    "Moreover, abstractions like hardware and software, presumably have problems when applied to biological systems, given that in these systems, every constituent likely serves both roles. If we can say, likely serves both structural and functional roles, in every relation we can abstract."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5543d3-d0d1-4404-8e4f-f518d83be04e",
   "metadata": {},
   "source": [
    "### Further Notes\n",
    "\n",
    "Reiterating what has been said by some cyberneticians throughout the last-century, any type of dynamical self-organizing system will inherently evolve towards a set of states representing an attractor in its state-space. What seems to be indeed unique to life and its derivatives (regarding larger-scale systems, as social ones), is that there's a characteristically low transition cost between basins (note that this is a generality, exceptions to this being common to where it's actually evolutionarily advantageous to have hard constraints on exploration), such that it can largely be instantiated by small changes to its constituents (\"order from noise\"). What needs to be noted, is that hard convergence to a set of states would presumably be a terrible adaptation, such that variance is irreversibly reduced, decreasing robustness capabilities. As such, on early time-scales on emergence of larger-scale systems, either of the extremes (hard or low convergence) are actually reasonable adaptations until competition increases. Following that, each of these larger-scale systems will have minmaxing strategies, so as to mantain reasonable exploration capacities without being exploited to failure.\n",
    "\n",
    "The superb adaption capabilities seen by biological systems, are presumably derived from the huge amount of memories that are possible to be allocated over all degrees of freedom of such systems, and being readily accessed with small effort."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750b395c-c929-4c10-ad1d-100f3e0347e6",
   "metadata": {},
   "source": [
    "### Some notes on Principles of Biological Autonomy - Francisco J. Varela, and related topics\n",
    "\n",
    "Majority of what I've been reiterating can be put under the guise of concepts like autopoiesis, closure of constraints, etc. As such, what seems to be unique to life is the capacity to maintain dynamic indentity. As long as the organization of relations that allowed the system to emerge in the first place is kept, the system is to be considered alive (if such system is considered autopoietic in the first place; note that this is a binary distinction; either the system in cause keeps closure of constraints or it doesn't). It doesn't matter what it takes for such to happen. Such a system will have internal adjustments so as to keep the topology of this organization, given a certain pertubation. And if such internal adjustment isn't enough, it will take a further compensation so as to meet this new pertubation. \n",
    "\n",
    "Given this, what immediately pops up is that life can be considered substrate invariant. The constitution of the system, doesn't matter much, as long as the relations between these are able to keep the conditions that lead to their emergence in the first place. Note that when the maintenance of topological organization is mentioned, such isn't to be considered rigid. There's going to be variability to such organization, just given the huge amount of possible pertubations. \n",
    "\n",
    "From this, we can say that life really only \"aims\" to maintain closure of constraints at a fundamental level. Anything else (i.e. reproduction, general plasticity, etc) can be seen as a compensation, or a byproduct, of trying to maintain closure of constraints when faced with respective pertubations. \n",
    "\n",
    "Where it really gets interesting, is when you take into consideration interactions between these autopoietic systems, and scaling in general. To the point, where we should question the link between these autopoietic capabilities and intelligence, further questioning if a larger scale autopoietic system can actually emerge from lower-scale non-autopoietic ones, or allopoietic systems.\n",
    "\n",
    "All of this to say, that we need better abstractions. We are never going to get over the barrier of introducting a pertubation to these autopoietic systems, by measuring them. Nonetheless, endlessly out-weighing approaches that seek to measure constituents, over ones that couldn't care less about these, is a sure enough way to put the study of the organism out of what is generally called biology.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63da3323-2afd-4b25-8d4d-3a76bd901d65",
   "metadata": {},
   "source": [
    "### More notes\n",
    "\n",
    "An arbitrary biological system has by virtue of its structural relationships a corresponding dynamics and a set of constraints that limit said dynamics. As such for the corresponding state-space, the set of states that are the most probable are said to be \"goal-states\". These \"goal-states\" change with time, as the corresponding state-space is morphed given both external inputs and internal compensations to said inputs, in order to mantain autopoietic control. With this view, we have the capability for an enormous amount of memory allocation, not only regarding the main system, but also relative to its progeny. Regarding this, lets imagine a certain system that learns a behaviour socially. As such, when reacting to the counterpart system, its own internal dynamics are changed. We can as such imagine, that a few degrees of freedom at a lower-scale are thus changed due to this larger-scale compensation (learning), and can be inherited by the relevant mechanisms of reproduction. The resulting systems, although not changed dramatically, would presumably have some of its state-space altered so that such behavioural response is more probable, specially when over multiple generations with said stimulus that lead to the respective learning response. This type of description can be linked more generally to Waddington's landscape, or to any other type of ideas that have a Lamarckian \"smell\". Nonetheless, this type of occurence is not necessarily just epigenetic (if it even makes sense to only compare it to genetic inheritance). It is a much more general phenomenon of how to allow the transmission of coarse-grained information over different scales, and over multiple generations (If one here takes the view of reproduction as a compensation in order to mantain autopoiesis. As an example, one could take a primitive type of binary fission as a reasonable strategy to dillute inhibitory molecules to components that are otherwise essential to maintenance of autopoiesis.).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3e6a0d-2ff5-4c7d-bde8-f410c1b070df",
   "metadata": {},
   "source": [
    "#### Random remark\n",
    "\n",
    "How many of these so supposed hallmarks of certain diseases might not be seen as compensations in order to maintain homeostasis, instead of themselves actually leading to a pathogenic phenotype? The causation is both upwards and downwards. How would you actually reduce such phenotype by either inhibiting expression of such metabolites for example, or downright inhibiting the \"responsible\" pathways, if any of these molecules are mere compensations. There might presumably me worsening of such phenotype, in these cases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
